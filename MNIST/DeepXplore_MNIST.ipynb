{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepXplore_MNIST.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1pFekEz1mEe5XOVMYn1e0y_1_iZ48htEN","authorship_tag":"ABX9TyN751ArLfX+JmhIAB66qBT9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# After Download the files on google drive\n","\n","You can download at [HERE](!https://github.com/GwiHwan-Go/deepxXplore.git).\n","\n","Tap the green button and download the repository and upload on google drive."],"metadata":{"id":"rFWOv1bvhAzp"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iVHZ0EvotfYy","executionInfo":{"status":"ok","timestamp":1655634536482,"user_tz":-540,"elapsed":87668,"user":{"displayName":"고귀환","userId":"14028709888910562996"}},"outputId":"1ed6f8d5-8692-4d53-f79c-839cf7905d94"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Enter the foldername in your Drive where you have saved the repository\n","# for my case, e.g. 'DNN_Testing/deepxXplore/MNIST'\n","FOLDERNAME = 'DNN_Testing/deepxXplore/MNIST'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))\n","\n","%cd /content/drive/My\\ Drive/$FOLDERNAME"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3ICWIGX6YgO","executionInfo":{"status":"ok","timestamp":1655558923151,"user_tz":-540,"elapsed":270,"user":{"displayName":"고귀환","userId":"14028709888910562996"}},"outputId":"58c11b48-b270-4a28-a9c5-cf6806810a77"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/DNN_Testing/deepxXplore/MNIST\n"]}]},{"cell_type":"code","source":["'''\n","usage: python gen_diff.py -h\n","'''\n","\n","from __future__ import print_function\n","\n","import argparse\n","\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.layers import Input\n","from imageio import imread\n","\n","from Model1 import Model1\n","from Model2 import Model2\n","from Model3 import Model3\n","from configs import bcolors\n","from utils import *\n","\n","# read the parameter\n","# argument parsing\n","\"\"\"\n","parser = argparse.ArgumentParser(description='Main function for difference-inducing input generation in MNIST dataset')\n","parser.add_argument('transformation', help=\"realistic transformation type\", choices=['light', 'occl', 'blackout'])\n","parser.add_argument('weight_diff', help=\"weight hyperparm to control differential behavior\", type=float)\n","parser.add_argument('weight_nc', help=\"weight hyperparm to control neuron coverage\", type=float)\n","parser.add_argument('step', help=\"step size of gradient descent\", type=float)\n","parser.add_argument('seeds', help=\"number of seeds of input\", type=int)\n","parser.add_argument('grad_iterations', help=\"number of iterations of gradient descent\", type=int)\n","parser.add_argument('threshold', help=\"threshold for determining neuron activated\", type=float)\n","parser.add_argument('-t', '--target_model', help=\"target model that we want it predicts differently\",\n","                    choices=[0, 1, 2], default=0, type=int)\n","parser.add_argument('-sp', '--start_point', help=\"occlusion upper left corner coordinate\", default=(0, 0), type=tuple)\n","parser.add_argument('-occl_size', '--occlusion_size', help=\"occlusion size\", default=(10, 10), type=tuple)\n","args = parser.parse_args(args=[])\n","\"\"\"\n","\n","args = argparse.Namespace(\n","    transformation='light',\n","    weight_diff=0.5,\n","    weight_nc=0.5,\n","    step=0.5,\n","    seeds=1,\n","    grad_iterations=1,\n","    threshold=0.4,\n","    target_model=0,\n","    start_point=(0, 0),\n","    occlusion_size=(10, 10),\n","\n",")\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","# the data, shuffled and split between train and test sets\n","(_, _), (x_test, _) = mnist.load_data()\n","\n","x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","input_shape = (img_rows, img_cols, 1)\n","\n","x_test = x_test.astype('float32')\n","x_test /= 255\n","\n","# define input tensor as a placeholder\n","input_tensor = Input(shape=input_shape)\n","\n","# load multiple models sharing same input tensor\n","model1 = Model1(input_tensor=input_tensor)\n","model2 = Model2(input_tensor=input_tensor)\n","model3 = Model3(input_tensor=input_tensor)\n","\n","# init coverage table\n","model_layer_dict1, model_layer_dict2, model_layer_dict3 = init_coverage_tables(model1, model2, model3)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzZzPQ8vAMHT","executionInfo":{"status":"ok","timestamp":1655569991176,"user_tz":-540,"elapsed":654,"user":{"displayName":"고귀환","userId":"14028709888910562996"}},"outputId":"d2aa3b8c-7f52-4d69-9429-1c3c0c0fdb04"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[94mModel1 loaded\u001b[0m\n","\u001b[94mModel2 loaded\u001b[0m\n","\u001b[94mModel3 loaded\u001b[0m\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","tf.executing_eagerly()\n","\n","\n","# ==============================================================================================\n","# start gen inputs\n","for _ in range(args.seeds):\n","    gen_img = np.expand_dims(random.choice(x_test), axis=0)\n","    orig_img = gen_img.copy()\n","    # first check if input already induces differences\n","    label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(\n","        model3.predict(gen_img)[0])\n","\n","    if not label1 == label2 == label3:\n","        print(bcolors.OKGREEN + 'input already causes different outputs: {}, {}, {}'.format(label1, label2,\n","                                                                                            label3) + bcolors.ENDC)\n","\n","        update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n","        update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n","        update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n","\n","        print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n","              % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n","                 neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n","                 neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n","        averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n","                       neuron_covered(model_layer_dict3)[0]) / float(\n","            neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n","            neuron_covered(model_layer_dict3)[\n","                1])\n","        print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n","\n","        gen_img_deprocessed = deprocess_image(gen_img)\n","\n","        # save the result to disk\n","        imsave('./generated_inputs/' + 'already_differ_' + str(label1) + '_' + str(\n","            label2) + '_' + str(label3) + '.png', gen_img_deprocessed)\n","        continue\n","\n","    # if all label agrees\n","    orig_label = label1\n","    layer_name1, index1 = neuron_to_cover(model_layer_dict1)\n","    layer_name2, index2 = neuron_to_cover(model_layer_dict2)\n","    layer_name3, index3 = neuron_to_cover(model_layer_dict3)\n","\n","    # construct joint loss function\n","    if args.target_model == 0:\n","        loss1 = -args.weight_diff * K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n","        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n","        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n","    elif args.target_model == 1:\n","        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n","        loss2 = -args.weight_diff * K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n","        loss3 = K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n","    elif args.target_model == 2:\n","        loss1 = K.mean(model1.get_layer('before_softmax').output[..., orig_label])\n","        loss2 = K.mean(model2.get_layer('before_softmax').output[..., orig_label])\n","        loss3 = -args.weight_diff * K.mean(model3.get_layer('before_softmax').output[..., orig_label])\n","    loss1_neuron = K.mean(model1.get_layer(layer_name1).output[..., index1])\n","    loss2_neuron = K.mean(model2.get_layer(layer_name2).output[..., index2])\n","    loss3_neuron = K.mean(model3.get_layer(layer_name3).output[..., index3])\n","    layer_output = (loss1 + loss2 + loss3) + args.weight_nc * (loss1_neuron + loss2_neuron + loss3_neuron)\n","\n","    # for adversarial image generation\n","    final_loss = K.mean(layer_output)\n","    \n","    with tf.GradientTape() as tape:\n","    # we compute the gradient of the input picture wrt this loss\n","      grads = normalize(tape.gradients(final_loss, input_tensor)[0])\n","\n","    # this function returns the loss and grads given the input picture\n","    iterate = K.function([input_tensor], [loss1, loss2, loss3, loss1_neuron, loss2_neuron, loss3_neuron, grads])\n","\n","    # we run gradient ascent for 20 steps\n","    for iters in xrange(args.grad_iterations):\n","        loss_value1, loss_value2, loss_value3, loss_neuron1, loss_neuron2, loss_neuron3, grads_value = iterate(\n","            [gen_img])\n","        if args.transformation == 'light':\n","            grads_value = constraint_light(grads_value)  # constraint the gradients value\n","        elif args.transformation == 'occl':\n","            grads_value = constraint_occl(grads_value, args.start_point,\n","                                          args.occlusion_size)  # constraint the gradients value\n","        elif args.transformation == 'blackout':\n","            grads_value = constraint_black(grads_value)  # constraint the gradients value\n","\n","        gen_img += grads_value * args.step\n","        predictions1 = np.argmax(model1.predict(gen_img)[0])\n","        predictions2 = np.argmax(model2.predict(gen_img)[0])\n","        predictions3 = np.argmax(model3.predict(gen_img)[0])\n","\n","        if not predictions1 == predictions2 == predictions3:\n","            update_coverage(gen_img, model1, model_layer_dict1, args.threshold)\n","            update_coverage(gen_img, model2, model_layer_dict2, args.threshold)\n","            update_coverage(gen_img, model3, model_layer_dict3, args.threshold)\n","\n","            print(bcolors.OKGREEN + 'covered neurons percentage %d neurons %.3f, %d neurons %.3f, %d neurons %.3f'\n","                  % (len(model_layer_dict1), neuron_covered(model_layer_dict1)[2], len(model_layer_dict2),\n","                     neuron_covered(model_layer_dict2)[2], len(model_layer_dict3),\n","                     neuron_covered(model_layer_dict3)[2]) + bcolors.ENDC)\n","            averaged_nc = (neuron_covered(model_layer_dict1)[0] + neuron_covered(model_layer_dict2)[0] +\n","                           neuron_covered(model_layer_dict3)[0]) / float(\n","                neuron_covered(model_layer_dict1)[1] + neuron_covered(model_layer_dict2)[1] +\n","                neuron_covered(model_layer_dict3)[\n","                    1])\n","            print(bcolors.OKGREEN + 'averaged covered neurons %.3f' % averaged_nc + bcolors.ENDC)\n","\n","            gen_img_deprocessed = deprocess_image(gen_img)\n","            orig_img_deprocessed = deprocess_image(orig_img)\n","\n","            # save the result to disk\n","            imsave('./generated_inputs/' + args.transformation + '_' + str(predictions1) + '_' + str(\n","                predictions2) + '_' + str(predictions3) + '.png',\n","                   gen_img_deprocessed)\n","            imsave('./generated_inputs/' + args.transformation + '_' + str(predictions1) + '_' + str(\n","                predictions2) + '_' + str(predictions3) + '_orig.png',\n","                   orig_img_deprocessed)\n","            break\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":479},"id":"Y5K_viuTFtSC","executionInfo":{"status":"error","timestamp":1655570725202,"user_tz":-540,"elapsed":273,"user":{"displayName":"고귀환","userId":"14028709888910562996"}},"outputId":"8d0ebfa4-469a-4ee8-bcbb-1d1c07a8e283"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-41-c502776d5433>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0morig_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# first check if input already induces differences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     label1, label2, label3 = np.argmax(model1.predict(gen_img)[0]), np.argmax(model2.predict(gen_img)[0]), np.argmax(\n\u001b[0m\u001b[1;32m     12\u001b[0m         model3.predict(gen_img)[0])\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/version_utils.py\u001b[0m in \u001b[0;36mdisallow_legacy_graph\u001b[0;34m(cls_name, method_name)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;34mf\"enabled. Please construct your `{cls_name}` instance in graph mode or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         f\" call `{cls_name}.{method_name}` with eager mode enabled.\")\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Calling `Model.predict` in graph mode is not supported when the `Model` instance was constructed with eager mode enabled. Please construct your `Model` instance in graph mode or call `Model.predict` with eager mode enabled."]}]}]}